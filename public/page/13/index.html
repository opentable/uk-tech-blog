<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><meta name="author" content="OpenTable"><link rel="icon" href="/favicon.png"><title>OpenTable Tech UK Blog</title><meta name="description"><link rel="alternate" type="application/rss+xml" title="OpenTable Tech UK Blog" href="/atom.xml"><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/main.css"><script src="//fonts.otstatic.com/zys4lfz.js"></script><link rel="stylesheet" href="/css/highlight.css">
</head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class="container-fluid"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#main-navbar" class="navbar-toggle"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand">OpenTable Tech UK Blog</a></div><div id="main-navbar" class="collapse navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/about/">About</a></li><li><a href="/archives/">Archive</a></li><li><a href="/blog/authors/">Authors</a></li></ul></div><div class="avatar-container"><div class="avatar-img-border"><a href="/"><img src="/opentable.png" class="avatar-img"></a></div></div></div></nav><div id="header-big-imgs" data-num-img='3' data-img-src-1="/bigimgs/building.jpg" data-img-desc-1="Alphabeta Building" data-img-src-2="/bigimgs/kitchen.jpg" data-img-desc-2="OpenTable London office" data-img-src-3="/bigimgs/office.jpg" data-img-desc-3="OpenTable Engineers"></div><header class="header-section has-img"><div class="intro-header big-img"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="page-heading"><h1>OpenTable Tech UK Blog</h1><hr class="small"><span class="page-subheading">The technology blog for OpenTable UK.</span></div></div></div></div><span class="img-desc"></span></div></header><div role="main" class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="posts-list"><article class="post-preview"><a href="/blog/2013/09/11/counting-in-elastic-search/"><h2 class="post-title">Counting in ElasticSearch</h2></a><p class="post-meta">Posted on 11 September 2013 · <a href="/blog/categories/ElasticSearch/" class="tag post-meta">ElasticSearch</a> · <a href="/blog/categories/Count/" class="tag post-meta">Count</a> · <a href="/blog/categories/Search/" class="tag post-meta">Search</a> · <a href="/blog/categories/PlainElastic-Net/" class="tag post-meta">PlainElastic.Net</a></p><div class="post-entry"><blockquote>
<p>Counting is the religion of this generation it is its hope and its salvation.<br>Gertrude Stein</p>
</blockquote>
<p>In our NeverEnding quest to provide better experience to the users we utilise user behaviour logs to influence future results. One particular case is restaurant popularity, which is indicated by many factors, for example how often it is searched and viewed.</p>
<p>In this blog post we will look into multiple ways of counting documents in Elastic Search which is crucial for this kind of activity. All examples here are provided using Elastic Search HTTP interface and code examples implemented with <a href="https://github.com/Yegoroff/PlainElastic.Net" target="_blank" rel="noopener">PlainElastic.NET</a> are <a href="https://gist.github.com/gondar/6320578" target="_blank" rel="noopener">available here</a></p>
<p>Before we make a deep dive into Elastic Search Counting options let’s define our expectations:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">So that I can order restaurants by those that are most searched</span><br><span class="line">As a potential diner</span><br><span class="line">I want the most searched statistics from the logs to be part of the search database</span><br></pre></td></tr></table></figure></p>
<p>Okay, that’s not exactly how our story was defined but as we don’t want to discuss the whole search infrastructure here, let’s assume this is sufficient.</p>
<p>Because we are eager engineers, we will quickly build some mock data against which to test our assumptions. Our restaurant name search logs look something like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;RestaurantId&quot; : 2,</span><br><span class="line">	&quot;RestaurantName&quot; : &quot;Restaurant Brian&quot;,</span><br><span class="line">	&quot;DateTime&quot; : &quot;2013-08-16T15:13:47.4833748+01:00&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>So we will populate our mock database with appropriate commands and check that all is in place:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:9200/store/item/ -XPOST -d &apos;&#123;&quot;RestaurantId&quot;:2,&quot;RestaurantName&quot;:&quot;Restaurant Brian&quot;,&quot;DateTime&quot;:&quot;2013-08-16T15:13:47.4833748+01:00&quot;&#125;&apos;</span><br><span class="line">curl http://localhost:9200/store/item/ -XPOST -d &apos;&#123;&quot;RestaurantId&quot;:1,&quot;RestaurantName&quot;:&quot;Restaurant Cecil&quot;,&quot;DateTime&quot;:&quot;2013-08-16T15:13:47.4833748+01:00&quot;&#125;&apos;</span><br><span class="line">curl http://localhost:9200/store/item/ -XPOST -d &apos;&#123;&quot;RestaurantId&quot;:1,&quot;RestaurantName&quot;:&quot;Restaurant Cecil&quot;,&quot;DateTime&quot;:&quot;2013-08-16T15:13:47.4833748+01:00&quot;&#125;&apos;</span><br><span class="line">curl http://localhost:9200/store/item/_search?q=*\&amp;pretty</span><br></pre></td></tr></table></figure></p>
<p>Our expected output is a count of documents for each restaurant. For example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;Restaurant Brian&quot; : 1</span><br><span class="line">	&quot;Restaurant Cecil&quot; : 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>There are three ways this can be achieved in Elastic Search; using count API (which seems like the most obvious way), a search with type set to count, or using facets to generate counts of all objects grouped by given property. Let’s compare them:</p>
<h3 id="Count-API"><a href="#Count-API" class="headerlink" title="Count API"></a>Count API</h3></div><a href="/blog/2013/09/11/counting-in-elastic-search/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven/"><h2 class="post-title">Grunt + Vagrant = Acceptance Test Heaven</h2></a><p class="post-meta">Posted on 16 August 2013 · <a href="/blog/categories/Acceptance-tests/" class="tag post-meta">Acceptance tests</a> · <a href="/blog/categories/Automation/" class="tag post-meta">Automation</a> · <a href="/blog/categories/Grunt/" class="tag post-meta">Grunt</a> · <a href="/blog/categories/Vagrant/" class="tag post-meta">Vagrant</a></p><div class="post-entry"><p>My continued love affair with Grunt reached a new high the other day, when I combined <a href="http://www.vagrantup.com" target="_blank" rel="noopener">Vagrant</a> with my <a href="/blog/2013/08/08/grunt-your-deployments-too/">Grunt deployment tasks</a> and test runners.</p>
<p>I’m not going to bang on about how great Vagrant is, because better people than me have already soliloquised at length on that subject. Let’s just take it as writ that <strong>Vagrant is awesome</strong>. </p>
<p>The objective is simple, we want to have a virtualised environment to run our acceptance tests against, that we can create and provision on demand, to ensure that our acceptance tests only deal with functional-correctness, not data- or environment-correctness.</p>
<p>I created a set of Grunt tasks which were able to do the following:</p>
<ul>
<li>Spin up an provision a Vagrant instance</li>
<li>Deploy the project code    </li>
<li>Start the server</li>
<li>Run the acceptance tests</li>
<li>Tear it all down</li>
</ul>
<p>All from a single command: <code>grunt acceptance</code></p>
<p>The price of this magic? About ten lines of Bash script, a six line Vagrantfile and some Grunt glue.</p>
<h2 id="Diving-in"><a href="#Diving-in" class="headerlink" title="Diving in"></a>Diving in</h2><p>Assuming you’ve got Vagrant installed, you can create a Vagrantfile in the root of your project, which looks like this:</p>
<pre><code>Vagrant.configure(&quot;2&quot;) do |config|
    config.vm.box = &quot;Ubuntu precise 64 VMWare&quot;
    config.vm.box_url = &quot;http://files.vagrantup.com/precise64_vmware.box&quot;
    config.vm.network :forwarded_port, guest: 3000, host: 3000
    config.vm.provision :shell, :path =&gt; &quot;setup/bootstrap.sh&quot;
end
</code></pre></div><a href="/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/08/08/grunt-your-deployments-too/"><h2 class="post-title">Grunt your deployments too</h2></a><p class="post-meta">Posted on 8 August 2013 · <a href="/blog/categories/JavaScript/" class="tag post-meta">JavaScript</a> · <a href="/blog/categories/Grunt/" class="tag post-meta">Grunt</a> · <a href="/blog/categories/Deployment/" class="tag post-meta">Deployment</a></p><div class="post-entry"><p>We’ve been using <a href="http://www.gruntjs.com" target="_blank" rel="noopener">Grunt</a> as a build tool for our nodejs apps, and it’s brilliant. It lints, it configures, it minifies, it tests and it packages.</p>
<p>As we move towards getting our first node app into production, we were looking at ways to deploy it. First we thought of <a href="http://www.capistranorb.com" target="_blank" rel="noopener">Capistrano</a>.</p>
<p><strong><em>Capistrano</em></strong> is a fully featured deployment framework written in ruby and levering rake style tasks. It’s extremely powerful and very robust, plus there is a <a href="https://github.com/loopj/capistrano-node-deploy" target="_blank" rel="noopener">gem for node deployments</a>. Alas, it was not to be. After half a day of tail chasing and hoop jumping, it occurred to me that there must be an easier way. Capistrano was encouraging me to make my project fit their template, rather than allowing me to configure the deployment to match my project. When I dug down into the Capistrano source, I found that it was just using ssh and sftp to run remote commands and copy files. But we can simplify this process.</p>
<p><strong><em>Grunt</em></strong> has been great so far, so I started looking at deploying directly through grunt. We would be deploying to Ubuntu server boxes, so the only tools necessary are ssh and sftp.</p>
<p>There are Grunt modules for nearly <a href="https://npmjs.org/search?q=grunt" target="_blank" rel="noopener">everything</a> (linting, minifying, testing, waiting, packaging, shell-exec’ing, tagging, etc.), and rather predictably, sshing (with sftp).</p>
<p><a href="https://github.com/andrewrjones/grunt-ssh" target="_blank" rel="noopener">Grunt-ssh</a> provides tasks for executing remote ssh commands, and for copying files using ssh. Let’s dive into some code.</p>
<p><strong><em>SSH commands</em></strong></p>
<p>This is going to go over some old ground (available on the Grunt-ssh <a href="https://github.com/andrewrjones/grunt-ssh" target="_blank" rel="noopener">readme</a>), but we can build up the commands pretty quick.</p>
<p>This is the basic config for executing ssh commands from your Gruntfile:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">module.exports = function(grunt) &#123;</span><br><span class="line">  	grunt.initConfig(&#123;</span><br><span class="line">    	sshexec: &#123;</span><br><span class="line">      uptime: &#123;</span><br><span class="line">        command: &quot;uptime&quot;,</span><br><span class="line">        options: &#123;</span><br><span class="line">          host: &quot;127.0.0.1&quot;,</span><br><span class="line">          port: 22</span><br><span class="line">          username: &quot;myuser&quot;,</span><br><span class="line">          password: &quot;mypass&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  // Load the plugin that provides the &quot;sshexec&quot; task.</span><br><span class="line">  grunt.loadNpmTasks(&apos;grunt-ssh&apos;);</span><br><span class="line"></span><br><span class="line">  // Default task.</span><br><span class="line">  grunt.registerTask(&apos;default&apos;, [&apos;sshexec:uptime&apos;]);</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></div><a href="/blog/2013/08/08/grunt-your-deployments-too/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/08/07/mapreduce-in-mongodb/"><h2 class="post-title">MapReduce in MongoDB</h2></a><p class="post-meta">Posted on 7 August 2013 · <a href="/blog/categories/Innovation/" class="tag post-meta">Innovation</a> · <a href="/blog/categories/JavaScript/" class="tag post-meta">JavaScript</a> · <a href="/blog/categories/MapReduce/" class="tag post-meta">MapReduce</a> · <a href="/blog/categories/MongoDB/" class="tag post-meta">MongoDB</a></p><div class="post-entry"><p>One of the first things I took on when joining OpenTable was building a new endpoint in our reviews API to aggregate and summarise restaurant review data. Thankfully, at the time, all the data I needed was cached in memory so building the response object was a simple set of linq queries over the cached reviews.</p>
<h2 id="The-problem"><a href="#The-problem" class="headerlink" title="The problem"></a>The problem</h2><p>Over time the number of reviews grow, and grow, and grow!  In fact it is inevitable that, in time, it will reach a point where caching all this data in memory would be madness.  One option to mitigate this would be to limit the cache to a fixed date range but this won’t work in this instance because the summary logic supports custom date ranges.  Another option would be to pull the data from the persistence store each and every time it’s required however this would seriously impact load on the infrastructure and degrade performance of the API.</p>
<p>We like to be proactive at OpenTable, so during innovation time (yes! we get time to innovate on our development) I looked at finding an alternate solution that would meet the requirements of the logic and wouldn’t drastically increase load or degrade performance.</p>
<h2 id="The-solution"><a href="#The-solution" class="headerlink" title="The solution"></a>The solution</h2><p>MongoDB supports <a href="http://en.wikipedia.org/wiki/MapReduce" target="_blank" rel="noopener">MapReduce</a> which allows processing large volumes of data (Map), running arbitrary logic to summarise (Reduce) and producing some results.  In MongoDB the MapReduce functionality uses JavaScript functions to perform the map and reduce steps and the syntax is relatively simple to understand:-</p>
<pre><code>db.largeDataset.mapReduce(mapFunction, 
                          reduceFunction, 
                          { out: &quot;summary&quot; }
</code></pre><p>In the above example the largeDataset collection is mapped using the predefined mapFunction, the results are passed to the reduceFunction and the reduced data is finally stored in the summary collection. On top of this you can specify queries as well as a finalize function to “tweak” the reduce results.</p>
<p>Because map, reduce &amp; finalize are functions that only operate on their inputs the workload can be parallelized although the final results would be stored in one location.</p>
<h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4></div><a href="/blog/2013/08/07/mapreduce-in-mongodb/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine/"><h2 class="post-title">Using Vagrant to work with ElasticSearch on your local machine</h2></a><p class="post-meta">Posted on 5 August 2013 · <a href="/blog/categories/ElasticSearch/" class="tag post-meta">ElasticSearch</a> · <a href="/blog/categories/Vagrant/" class="tag post-meta">Vagrant</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a></p><div class="post-entry"><p>Recently, I have started to work a lot more with <a href="http://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant</a> as a tool for creating a standard development environment across my team. This essentially means that regardless what the developers’ machine is set up or running as, they can still reproduce the same environment as their colleagues just by entering a command. </p>
<p>Configuration managgement is something we have had to embrace to help us maintain an ever changing world of technologies. The hardest thing is knowing what we actually have to build in these environments. We use Vagrant to help us understand this. The simple flow is as follows:</p>
<ul>
<li>Developer starts a new project</li>
<li>Developer creates a Vagrantfile to spin up a local VM</li>
<li>Vagrantfile gets iterated on as the development process goes forward</li>
</ul>
<p>Once the developer understands what they need to actually run their software, we would then go about creating an environment to which this software will actually be deployed for end-to-end testing. I won’t go any further into the details of our Vagrant flow in this post, if you want to read more about how to get started with Vagrant, then I would suggest reading <a href="http://shop.oreilly.com/product/0636920026358.do" target="_blank" rel="noopener">Vagrant Up and Running</a> by <a href="https://twitter.com/mitchellh" target="_blank" rel="noopener">Mitchell Hashimoto</a>.</p>
<h2 id="Vagrant-and-ElasticSearch"><a href="#Vagrant-and-ElasticSearch" class="headerlink" title="Vagrant and ElasticSearch"></a>Vagrant and ElasticSearch</h2><p>Whilst reviewing a book on <a href="http://www.elasticsearch.org/" target="_blank" rel="noopener">ElasticSearch</a>, I noticed how simple the instructions were to get up and running with ElasticSearch. Please note, that there are already lots of Puppet modules for configuring ElasticSearch on <a href="http://forge.puppetlabs.com/modules?q=elasticsearch" target="_blank" rel="noopener">Puppetlabs Forge</a>. This post only talks about how I was able to quickly spin up some local instances. I didn’t want to manually do this, so I decided to use Vagrant (and Puppet) to take care of it for me. The instructions can be summarised as follows:</p>
<ul>
<li>Download and install the JavaSDK</li>
<li>Download the specific ElasticSearch package</li>
<li>Install ElasticSearch</li>
<li>Download and install curl (to be able to interact with ElasticSearch)</li>
<li>Make sure the service is started</li>
</ul>
<p>I hate doing this manually. Luckily, with the correct script, I am able to automate all of this as follows:</p>
<pre><code>Vagrant.configure(&quot;2&quot;) do |config|
    config.vm.box = &quot;Ubuntu precise 64 VMWare&quot;
    config.vm.box_url = &quot;http://files.vagrantup.com/precise64_vmware.box&quot;
    config.vm.network :forwarded_port, guest: 9200, host: 9200
    config.vm.provision :puppet do |puppet|
        puppet.module_path = &apos;../setup/modules&apos;
        puppet.manifests_path = &apos;../setup/manifests&apos;
        puppet.manifest_file = &apos;default.pp&apos;
        puppet.options = &apos;--verbose --debug&apos;
    end
end
</code></pre><p>Essentially, this script says to create a clone of a VM from a predefined box, forward port 9200 on the vm to 9200 on my local machine and then provision the server using Puppet. The Puppet script works as follows:</p></div><a href="/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine/" class="post-read-more">[Read More]</a></article></div><ul class="pager main-pager"><li class="previous"><a href="/page/12">← Newer Posts</a></li><li class="next"><a href="/page/14">Older Posts →</a></li></ul></div></div></div><footer><div class="container beautiful-jekyll-footer"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href="https://github.com/opentable" title="GitHub"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-github"></i></span></a></li><li><a href="https://twitter.com/opentabletechuk" title="Twitter"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-twitter"></i></span></a></li><li><a href="https://www.linkedin.com/company/12181" title="LinkedIn"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-linkedin"></i></span></a></li><li><a href="http://stackoverflow.com/jobs/companies/opentable" title="StackOverflow"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-stack-overflow"></i></span></a></li></ul><p class="copyright text-muted">© OpenTable • 2019 • <a href="mailto:undefined"></a>
</p><p class="theme-by text-muted">Theme by
<a href="https://github.com/twoyao/beautiful-hexo">beautiful-hexo</a></p></div></div></div></footer><script src="/js/jquery-1.11.2.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/main.js"></script><script src="/js/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script>(function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
    a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
ga('create', 'UA-2621903-16', 'auto');
ga('send', 'pageview');</script></body></html>